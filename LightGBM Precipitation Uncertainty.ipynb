{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4XMSaIerRSB",
    "outputId": "58309fe1-9639-42d3-a6be-c8fab12e5e0d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtU8oy9o-5-w"
   },
   "outputs": [],
   "source": [
    "wd = pd.read_feather('Dados_Jan1980_mar2020_interpolado.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LseHbCGaOw3k",
    "outputId": "9b92ff5d-f051-48b7-a335-2b32aa910585"
   },
   "outputs": [],
   "source": [
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX0tt7ohAvrk"
   },
   "outputs": [],
   "source": [
    "# Reordena por localidade ao invés de ano.\n",
    "wdc = wd.sort_values(by=['lat', 'lon'])\n",
    "\n",
    "# Adiciona mais uma coluna para representar o 'y'\n",
    "wdc['prec_GPCP_roll'] = np.roll(wdc['prgpcp'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_H_QBztFzc6U",
    "outputId": "d491fc39-26e2-4d69-8e12-dac192c6da74"
   },
   "outputs": [],
   "source": [
    "wdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-gmhJ5bE5NU"
   },
   "outputs": [],
   "source": [
    "wdc = wdc.loc[wdc['year'] < 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ikxOZnWtz_I8",
    "outputId": "51f15147-caa2-438f-e6ca-2e56e03bdab4"
   },
   "outputs": [],
   "source": [
    "wdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO3ilxDgOwAv"
   },
   "outputs": [],
   "source": [
    "class PrecModel:\n",
    "\n",
    "    def __init__(self, data, split_year, train_size, name):\n",
    "        self.data = data\n",
    "        self.train_size = train_size\n",
    "        self.name = name\n",
    "\n",
    "        # Fit normalization to current data\n",
    "\n",
    "        self.x_scaler = MinMaxScaler()\n",
    "        self.x_scaler.fit(data.loc[:, 'temp850':'prgpcp'])\n",
    "\n",
    "        self.y_scaler = MinMaxScaler()\n",
    "        self.y_scaler.fit(data.loc[:, 'prec_GPCP_roll'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        # Split train and test set\n",
    "\n",
    "        self.trainval_data = data.loc[data['year'] < split_year]\n",
    "        self.test_data = data.loc[data['year'] >= split_year]\n",
    "\n",
    "        # Normalize training data\n",
    "\n",
    "        self.X = self.x_scaler.transform(self.trainval_data.loc[:, 'temp850':'prgpcp'].values)\n",
    "        self.y = self.y_scaler.transform(self.trainval_data.loc[:, 'prec_GPCP_roll'].values.reshape(-1, 1))\n",
    "\n",
    "        # Normalize test data\n",
    "\n",
    "        self.test_data_input = self.test_data.loc[:, 'temp850':'prgpcp']\n",
    "        self.test_data_x = self.x_scaler.transform(self.test_data_input)\n",
    "        self.test_data_output = self.test_data.loc[:, 'prec_GPCP_roll']\n",
    "        self.test_data_y = self.y_scaler.transform(self.test_data_output.values.reshape(-1, 1))\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size=self.train_size,\n",
    "                                                               shuffle=True)\n",
    "\n",
    "    def _objective(self, trial):\n",
    "\n",
    "        if trial.number >= 100:\n",
    "            self.study.stop()\n",
    "            return\n",
    "\n",
    "        # Parâmetros a serem otimizados\n",
    "\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 256),\n",
    "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        }\n",
    "\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "\n",
    "        gbm = lgb.LGBMRegressor(**params, early_stopping_rounds=100)\n",
    "\n",
    "        n_scores = cross_val_score(gbm, self.X_train, self.y_train.ravel(),\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=cv, n_jobs=-1, error_score='raise',\n",
    "                                   fit_params={'eval_metric': 'l2', 'eval_set': [(self.X_test, self.y_test.flatten())]})\n",
    "\n",
    "        return np.mean(np.abs(n_scores))\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        # Optimize\n",
    "\n",
    "        study_name = 'lgb-{}'.format(self.name)\n",
    "        storage_name = \"sqlite:///lgb-{}.db\".format(self.name)\n",
    "\n",
    "        self.study = optuna.create_study(direction=\"minimize\",\n",
    "                                         pruner=optuna.pruners.HyperbandPruner(),\n",
    "                                         study_name=study_name,\n",
    "                                         storage=storage_name,\n",
    "                                         load_if_exists=True)\n",
    "\n",
    "        self.study.optimize(self._objective, n_trials=500)\n",
    "        DX = lgb.Dataset(self.X_train, self.y_train.flatten())\n",
    "        Dval = lgb.Dataset(self.X_test, self.y_test.flatten())\n",
    "\n",
    "        self.bst = lgb.train(self.study.best_params, DX, num_boost_round=1000)\n",
    "\n",
    "    def _denorm_calc(self, y_scaler, y, pred, interval=3):\n",
    "        y_denorm = y_scaler.inverse_transform(y)\n",
    "        pred_denorm = y_scaler.inverse_transform(np.expand_dims(pred, 0))\n",
    "        diff = np.subtract(y_denorm.flatten(), pred_denorm.flatten())\n",
    "\n",
    "        ####\n",
    "        diff = pd.Series(diff)\n",
    "        unc = diff.rolling(3, center=True).var()\n",
    "        unc.iloc[0] = 0\n",
    "        unc.iloc[-1] = 0\n",
    "        ####\n",
    "\n",
    "        #years = np.array(np.array_split(diff, len(diff)//interval))\n",
    "        #var = np.var(years, axis=1)\n",
    "        #unc = np.repeat(var, interval)\n",
    "        return pred_denorm, unc\n",
    "\n",
    "    def train_test_error(self):\n",
    "        train_error = np.mean((self.y.flatten() - self.bst.predict(self.X))**2)\n",
    "        test_error = np.mean((self.test_data_y.flatten() - self.bst.predict(self.test_data_x))**2)\n",
    "        print(f\"Training error: {train_error}\")\n",
    "        print(f\"Test error: {test_error}\")\n",
    "\n",
    "    def time_series(self):\n",
    "        test_error = self.test_data_y.flatten() - self.bst.predict(self.test_data_x)\n",
    "        return test_error\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.study.best_params\n",
    "\n",
    "    def save_trials(self):\n",
    "\n",
    "        # Save all tries\n",
    "\n",
    "        df = self.study.trials_dataframe()\n",
    "        df.to_excel(\"best-params-lgb-{}.xlsx\".format(self.name))\n",
    "\n",
    "    def save_model(self):\n",
    "\n",
    "        self.bst.save_model('lgb_{}_model.txt'.format(self.name), num_iteration=self.bst.best_iteration)\n",
    "\n",
    "    def save_data(self):\n",
    "\n",
    "        train_pred = self.bst.predict(self.X)\n",
    "        train_pred_denorm, train_unc = self._denorm_calc(self.y_scaler, self.y, train_pred)\n",
    "        np.save(\"lgb-train-pred.npy\", train_pred_denorm)\n",
    "        np.save(\"lgb-train-unc.npy\", train_unc)\n",
    "\n",
    "        test_pred = self.bst.predict(self.test_data_x)\n",
    "        test_pred_denorm, test_unc = self._denorm_calc(self.y_scaler, self.test_data_y, test_pred)\n",
    "        np.save(\"lgb-test-pred.npy\", test_pred_denorm)\n",
    "        np.save(\"lgb-test-unc.npy\", test_unc)\n",
    "\n",
    "        dfprec = pd.DataFrame(test_pred_denorm[0], columns=['prec_lgb_denorm'])\n",
    "        dfprec.to_feather(\"prec_lgb_denorm.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdXwQiReCTDs",
    "outputId": "a8f3a0c5-01bb-4f61-f0c8-e63c324d187e"
   },
   "outputs": [],
   "source": [
    "Prec = PrecModel(wdc, 2018, 0.75, \"prec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gI7G8GugF9rg",
    "outputId": "81b35878-af49-41e8-cfd9-525836f891d0"
   },
   "outputs": [],
   "source": [
    "Prec.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ryXD8ajjjzJ",
    "outputId": "17502f91-a6ea-4669-9f43-8e74cd7208dc"
   },
   "outputs": [],
   "source": [
    "Prec.best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soaymTiiSDcp",
    "outputId": "97fe9bcd-0ef9-4dfb-8aad-c8b3adc98e92"
   },
   "outputs": [],
   "source": [
    "Prec.train_test_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afdRYF6HMwRs"
   },
   "outputs": [],
   "source": [
    "Prec.save_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8JeQzJOMxgk"
   },
   "outputs": [],
   "source": [
    "Prec.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbDKWeUvMzT6"
   },
   "outputs": [],
   "source": [
    "Prec.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHgPwfMHIGC4"
   },
   "outputs": [],
   "source": [
    "class UncModel(PrecModel):\n",
    "\n",
    "    def __init__(self, data, train_size, name):\n",
    "        self.data = data\n",
    "        self.train_size = train_size\n",
    "        self.name = name\n",
    "\n",
    "        # Fit normalization to current data\n",
    "\n",
    "        self.x_scaler = MinMaxScaler()\n",
    "        self.x_scaler.fit(data.loc[:, 'temp850':'unc'])\n",
    "\n",
    "        self.y_scaler = MinMaxScaler()\n",
    "        self.y_scaler.fit(data.loc[:, 'unc_roll'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        # Split train and test set\n",
    "\n",
    "        self.trainval_data = data.loc[data['year'] < 2018]\n",
    "        self.test_data = data.loc[data['year'] >= 2018]\n",
    "\n",
    "        # Normalize training data\n",
    "\n",
    "        self.X = self.x_scaler.transform(self.trainval_data.loc[:, 'temp850':'unc'].values)\n",
    "        self.y = self.y_scaler.transform(self.trainval_data.loc[:, 'unc_roll'].values.reshape(-1, 1))\n",
    "\n",
    "        # Normalize test data\n",
    "\n",
    "        self.test_data_input = self.test_data.loc[:, 'temp850':'unc']\n",
    "        self.test_data_x = self.x_scaler.transform(self.test_data_input)\n",
    "        self.test_data_output = self.test_data.loc[:, 'unc_roll']\n",
    "        self.test_data_y = self.y_scaler.transform(self.test_data_output.values.reshape(-1, 1))\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size=self.train_size,\n",
    "                                                               shuffle=True)\n",
    "\n",
    "    def save_data(self):\n",
    "        test_pred_unc = self.bst.predict(self.test_data_x)\n",
    "        y_unc_denorm = self.y_scaler.inverse_transform(self.test_data_y)\n",
    "        pred_unc_denorm = self.y_scaler.inverse_transform(np.expand_dims(test_pred_unc, 0))\n",
    "        dfunc = pd.DataFrame(pred_unc_denorm[0], columns=['lgb_unc_denorm'])\n",
    "        dfprec = pd.read_feather(\"prec_lgb_denorm.feather\")\n",
    "        df_final = pd.concat([self.test_data.reset_index(drop=True), dfprec, dfunc], axis=1)\n",
    "        df_final['prec_error_denorm'] = df_final['prgpcp'] - df_final['prec_lgb_denorm']\n",
    "        df_final['error_unc'] = df_final['unc_roll'] - df_final['lgb_unc_denorm']\n",
    "        df_final.to_excel('incerteza.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5J6KVBbCMPM"
   },
   "outputs": [],
   "source": [
    "train_unc = np.load(\"lgb-train-unc.npy\")\n",
    "test_unc = np.load(\"lgb-test-unc.npy\")\n",
    "\n",
    "traintest_unc = np.concatenate((train_unc, test_unc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2g24QvayCSQX",
    "outputId": "15542000-0f91-417f-bcb1-e9ac4ad67f12"
   },
   "outputs": [],
   "source": [
    "wdc.loc[:, 'unc'] = traintest_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfKxDa7pGW6h",
    "outputId": "749520d5-9798-4252-ed79-423892b7c8f9"
   },
   "outputs": [],
   "source": [
    "# Adiciona mais uma coluna para representar o 'y'\n",
    "wdc['unc_roll'] = np.roll(wdc['unc'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Uj4vUpm2lIav",
    "outputId": "798c9a0c-eade-46f3-86d1-ac486e5b1672"
   },
   "outputs": [],
   "source": [
    "wdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHugRbXMMaCM",
    "outputId": "d6121248-0435-4cd3-83e9-84ca55df17f4"
   },
   "outputs": [],
   "source": [
    "Unc = UncModel(wdc, 0.75, \"unc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cutFImgLCDI0",
    "outputId": "fef1e354-f537-45ad-83ab-7ed68b3de875"
   },
   "outputs": [],
   "source": [
    "Unc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIzU7Ot1j3UD",
    "outputId": "6c3de7d1-55fe-4ac2-aab3-638d622f5bff"
   },
   "outputs": [],
   "source": [
    "Unc.best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlgjshV1HNuQ",
    "outputId": "04838dd0-73e8-4aaf-fe9f-3480493d3735"
   },
   "outputs": [],
   "source": [
    "Unc.train_test_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NI7mHAq9C32Z"
   },
   "outputs": [],
   "source": [
    "Unc.save_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tWrWiWlDy_U"
   },
   "outputs": [],
   "source": [
    "Unc.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgM310YXb26W"
   },
   "outputs": [],
   "source": [
    "Unc.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hR_Fq6dYodfe"
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uh48S_HoKGCj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
